---
layout: about
title: "Weijia (Charlie) Zhang"
permalink: /
subtitle: This website is under construction. You can also check my another website [here](https://charliedreemur.wordpress.com).


profile:
  align: right
  image: my_pic.jpg
  image_circular: true # crops the image to make it circular
  more_info: >
    <p>University of Illinois at Urbana-Champaign</p>


selected_papers: false # includes a list of papers marked as "selected={true}"
social: true # includes social icons at the bottom of the page

announcements:
  enabled: false # includes a list of news items
  scrollable: false  # adds a vertical scroll bar if there are more than 3 news items
  limit: 5 # leave blank to include all the news in the `_news` folder

latest_posts:
  enabled: false
  scrollable: false # adds a vertical scroll bar if there are more than 3 new posts items
  limit: 3 # leave blank to include all the blog posts
---
Howdy! I'm Charlie Zhang!

- CS+Math @ [UIUC](https://illinois.edu/)

- GPA: 3.86/4.0 (2025 Dean’s List)

- AI Researcher & Full-Stack Programmer & Game Developer

Research
My research interests are in the field of LLM Agents, especially in next-generation AI agents that seamlessly bridge virtual and physical worlds through socially intelligent, tool-agnostic, and ethically grounded architectures, including:

- LLM Agents
- Multi-Agent Systems
- Persona Agent
- Multi-Modal Agents
  

Also some random research ideas:

1. Hyper-Realistic Game NPCs with Embodied Cognition
How can we create game agents that perceive (voice/image), remember (long-term context), and evolve (persona-driven traits) like humans while interacting with digital worlds?
→ I develop multi-modal NPCs integrating real-time speech (Whisper + GPT-SoVITs), physical interaction (Inverse Kinematics), and memory architectures (RAG + CoT).
→ Key innovations: Character-card-driven persona frameworks (Reborn Tech), procedural reward systems for emotional consistency (OpenManus-RL), Unity/Flask visualization for human-in-the-loop testing (Artificial Leviathan).
→ Goal: NPCs that learn from players and persist memories across gaming sessions.

1. Self-Evolving Tool-Creation Agents
Can agents autonomously generate, refine, and chain tools to solve novel problems—without human intervention?
→ I engineer MCP-compatible frameworks (OpenManus-RL) using RL + Mixture of Experts (MoE) to enable agents to:
 - Self-discover tools (e.g., creating Python scripts or API calls for unseen OS/Web/KG environments)
 - Optimize tool-chains via REACT reasoning (think→act→create→evaluate) with automated reward signals.
→ Key innovations: GAIA/WebArena benchmarking, cross-domain generalization via DeepSeek GRPO, synthetic tool-curation pipelines.
→ Goal: Agents that bootstrap their own toolkits for open-ended problem-solving.

1. Governance-Aware Social Agent Ecosystems
How do multi-agent societies negotiate ethical rules, mitigate biases, and sustain collaboration at scale?
→ I simulate emergent social contracts (Artificial Leviathan) using:
 - Persona-engineered agents (prompt + QA-encoded traits)
 - Bias-aware evolution (lessons from LLM data augmentation)
 - Human-AI policy co-creation (Unity/Flask visualization + governance rule extraction).
→ Key innovations: Hobbesian interaction frameworks, synthetic bias assessment benchmarks, policy generation from collective dynamics.
→ Goal: Scalable agent societies that self-regulate conflicts and align with human values.

Feel Free to reach me on [email](weijia4@illinois.edu)
